{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "from typing import Tuple, List, Dict, TypedDict, Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image, ImageDraw, JpegImagePlugin, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT = ImageFont.truetype('/usr/share/fonts/truetype/freefont/FreeSerif.ttf', 12)\n",
    "\n",
    "def build_image_name(image_id: int) -> str:\n",
    "    return f'{str(image_id).rjust(12, \"0\")}.jpg'\n",
    "\n",
    "\n",
    "def get_images_with_person(number_of_images: int = 10) -> List[int]:\n",
    "    with open('./annotations/instances_val2017.json', 'r') as _f:\n",
    "        instances = json.load(_f)\n",
    "\n",
    "        for category in instances['categories']:\n",
    "            if category['supercategory'] == 'person':\n",
    "                print(f'Category Person with id: {category[\"id\"]}')\n",
    "\n",
    "        persons_images = []\n",
    "        for ann in instances['annotations']:\n",
    "            if number_of_images:\n",
    "                if ann['category_id'] == 1:\n",
    "                    persons_images.append(build_image_name(ann['image_id']))\n",
    "                    number_of_images -= 1\n",
    "    return persons_images\n",
    "\n",
    "\n",
    "def draw_key_points(img: Image.Image, key_points: List[Tuple[str, List]]) -> Image.Image:\n",
    "    drawing = ImageDraw.Draw(img)\n",
    "    for point in key_points:\n",
    "        if point[1][2] != 0:\n",
    "            # drawing.point(xy=[point[1][0], point[1][1]], fill='blue')\n",
    "            drawing.ellipse(xy=[point[1][0], point[1][1], point[1][0] + 3, point[1][1] + 3], fill='blue')\n",
    "            drawing.text((point[1][0], point[1][1]), text=point[0], font=FONT)\n",
    "    return img\n",
    "\n",
    "\n",
    "def group_by_n_elements(iterable: List, number_of_elements: int) -> List:\n",
    "    return [iterable[x: x + number_of_elements] for x in range(0, len(iterable), number_of_elements)]\n",
    "\n",
    "\n",
    "def group_with_body_parts(coordinates: List) -> List:\n",
    "    body_parts = ['nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear', 'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow', 'left_wrist', 'right_wrist', 'left_hip', 'right_hip', 'left_knee', 'right_knee', 'left_ankle', 'right_ankle']\n",
    "    grouped = group_by_n_elements(iterable=coordinates, number_of_elements=3)\n",
    "    result = itertools.zip_longest(body_parts, grouped)\n",
    "    return list(result)\n",
    "\n",
    "\n",
    "def draw_bbox(img: JpegImagePlugin.JpegImageFile, points: Tuple[float, float, float, float]) -> ImageDraw.Draw:\n",
    "    \"\"\"Draws bbox on the image\"\"\"\n",
    "    x_coord, y_coord, width, height = points\n",
    "    img = img.convert('RGBA')\n",
    "    overlay = Image.new('RGBA', img.size, (255, 255, 255, 0))\n",
    "    draw = ImageDraw.Draw(overlay)\n",
    "    draw.rectangle((\n",
    "        (x_coord, y_coord), \n",
    "        (x_coord + width, y_coord + height)), \n",
    "        fill=(128,255,255,90), \n",
    "        outline=(210,255,255,120),\n",
    "        width=3\n",
    "    )\n",
    "    return Image.alpha_composite(img, overlay)\n",
    "\n",
    "\n",
    "def crop_bbox(img: JpegImagePlugin.JpegImageFile, points: Tuple[float, float, float, float]) -> ImageDraw.Draw:\n",
    "    # to_return = img.resize((256, 192), box=(points[0], points[1], points[0] + points[2], points[1] + points[3]))\n",
    "    to_return = img.resize((256, 192), box=(points[0], points[1], points[2], points[3]))\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying all objects and there classes on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "class DetectedPersons(TypedDict):\n",
    "    image: Optional[ImageDraw.Draw]\n",
    "    boxes: List[Tensor]\n",
    "        \n",
    "\n",
    "def detect_person_faster_cnn(path_to_image: str, model) -> DetectedPersons:\n",
    "    \"\"\"Detects persons on image and returns image with blist of bounding boxes\"\"\"\n",
    "    data_to_return = {'image': None, 'boxes': [], 'cropped': []}\n",
    "    with Image.open(path_to_image) as im:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            transform = transforms.Compose([transforms.ToTensor(), ])\n",
    "            tensor_image = transform(im)\n",
    "            tensor_image = torch.unsqueeze(tensor_image, 0)\n",
    "            output = model(tensor_image)\n",
    "            if output:\n",
    "                output = output[0]\n",
    "\n",
    "                for idx, label in enumerate(output['labels']):\n",
    "                    if label.item() == 1 and output['scores'][idx].item() > 0.99:  # if class number is 1\n",
    "                        data_to_return['boxes'].append(output['boxes'][idx])\n",
    "                        im = draw_bbox(img=im, points=output['boxes'][idx])\n",
    "                        cropped_image = crop_bbox(img=im.copy(), points=output['boxes'][idx])\n",
    "                        data_to_return['cropped'].append(cropped_image)\n",
    "\n",
    "    data_to_return['image'] = im\n",
    "    return data_to_return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category Person with id: 1\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "fast_cnn_model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "fast_cnn_model.eval()\n",
    "for param in fast_cnn_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# precision = 'fp32'\n",
    "# ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd', model_math=precision)\n",
    "#\n",
    "# ssd_model.eval()\n",
    "\n",
    "fig = plt.figure(figsize=(25, 20))\n",
    "\n",
    "image_ids = get_images_with_person(number_of_images=4)\n",
    "\n",
    "for idx, image_path in enumerate(image_ids):\n",
    "    result = detect_person_faster_cnn(path_to_image=f'./val2017/{image_path}', model=fast_cnn_model)\n",
    "    # result = detect_person_ssd(path_to_image=f'./val2017/{image_path}', model=ssd_model)\n",
    "    ax = fig.add_subplot(5, 3, idx + 1, xticks=[], yticks=[])\n",
    "    plt.imshow(result['image'])\n",
    "    ax.set_title('Person')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}